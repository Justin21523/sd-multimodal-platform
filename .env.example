# SD Multi-Modal Platform Configuration - Phase 3
# Copy this file to .env and customize for your environment

# =============================================================================
# API Configuration
# =============================================================================
API_PREFIX=/api/v1
HOST=0.0.0.0
PORT=8000
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080,http://127.0.0.1:3000

# =============================================================================
# Hardware Configuration
# =============================================================================
DEVICE=cuda
# Options: cuda, cpu, auto
# auto = automatically detect CUDA availability

# PyTorch Data Type
TORCH_DTYPE=float16
# Options: float32, float16, bfloat16
# float16 saves ~50% VRAM, recommended for most GPUs

# =============================================================================
# Model Configuration
# =============================================================================
PRIMARY_MODEL=sdxl-base
# Options: sdxl-base, sd-1.5, sd-2.1
# This model will be loaded on startup

# Model Paths (relative to project root)
SD_MODEL_PATH=./models/stable-diffusion
SDXL_MODEL_PATH=./models/sdxl
CONTROLNET_PATH=./models/controlnet
LORA_PATH=./models/lora
VAE_PATH=./models/vae

# =============================================================================
# Performance Optimization (RTX 5080 Ready)
# =============================================================================

# Attention Processor
USE_SDPA=true
# Use PyTorch Scaled Dot Product Attention (RTX 5080 recommended)

ENABLE_XFORMERS=false
# Use xFormers attention (may not work on RTX 5080/sm_120)
# Automatically falls back to SDPA if xFormers unavailable

# Memory Optimizations
USE_ATTENTION_SLICING=true
# Reduces VRAM usage by processing attention in slices

ENABLE_CPU_OFFLOAD=false
# Move unused models to CPU to save VRAM (slower inference)

ENABLE_MODEL_COMPILATION=false
# PyTorch 2.0+ model compilation (experimental)

# =============================================================================
# Generation Defaults
# =============================================================================
DEFAULT_WIDTH=1024
DEFAULT_HEIGHT=1024
DEFAULT_STEPS=25
DEFAULT_CFG=7.5
DEFAULT_SAMPLER=DPM++ 2M Karras

# =============================================================================
# Performance Limits
# =============================================================================
MAX_WORKERS=1
# Number of concurrent generation workers

MAX_BATCH_SIZE=4
# Maximum images per request

REQUEST_TIMEOUT=300
# Request timeout in seconds

MAX_FILE_SIZE=10MB
# Maximum upload file size

# =============================================================================
# Security Configuration
# =============================================================================
SECRET_KEY=your-super-secret-key-here
# Change this to a random string for production!

JWT_EXPIRE_HOURS=24
# JWT token expiration time

ENABLE_NSFW_FILTER=true
# Enable NSFW content detection and filtering

ENABLE_RATE_LIMITING=true
# Enable API rate limiting

# =============================================================================
# Storage Configuration
# =============================================================================
OUTPUT_PATH=./outputs
# Directory for generated images

ENABLE_METADATA_LOGGING=true
# Save generation metadata as JSON files

KEEP_GENERATIONS_DAYS=7
# Auto-cleanup generated files older than N days (0 = disabled)

# =============================================================================
# Logging Configuration
# =============================================================================
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR

ENABLE_REQUEST_LOGGING=true
# Log all API requests with timing

LOG_FILE_PATH=./logs/app.log
# Log file location

# =============================================================================
# Monitoring (Optional)
# =============================================================================
ENABLE_PROMETHEUS=false
# Enable Prometheus metrics endpoint

SENTRY_DSN=
# Sentry error tracking DSN (optional)

# =============================================================================
# Development Settings
# =============================================================================
DEBUG=false
# Enable debug mode (more verbose logging)

RELOAD=false
# Enable auto-reload on code changes

# =============================================================================
# Model Download Settings
# =============================================================================
HF_TOKEN=
# Hugging Face token for private models (optional)

USE_AUTH_TOKEN=false
# Use authentication token for model downloads

CACHE_DIR=./cache
# Cache directory for model downloads

# =============================================================================
# Phase 3 Specific Settings
# =============================================================================
AUTO_MODEL_SWITCHING=true
# Allow automatic model switching based on prompts

PRELOAD_MODELS=false
# Preload multiple models into memory (requires lots of VRAM)

ENABLE_MODEL_CACHING=true
# Cache model components for faster switching

GENERATION_QUEUE_SIZE=100
# Maximum pending generation requests

# =============================================================================
# Experimental Features
# =============================================================================
ENABLE_CONTROLNET=false
# Enable ControlNet support (Phase 4)

ENABLE_LORA=false
# Enable LoRA support (Phase 4)

ENABLE_VIDEO_GENERATION=false
# Enable video generation (Phase 8)

ENABLE_BATCH_API=false
# Enable batch processing endpoints (Phase 8)